{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Plotting stats raw context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loader = np.load('/media/Data/flipvanrijn/datasets/coco/processed/reduced/context_train_filtered_stemmed.npz')\n",
    "data_train = loader['data']\n",
    "loader = np.load('/media/Data/flipvanrijn/datasets/coco/processed/reduced/context_val_filtered_stemmed.npz')\n",
    "data_val = loader['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_lengths(data):\n",
    "    # Count with the same length\n",
    "    lengths = {}\n",
    "    for d in data:\n",
    "        length = len(d)\n",
    "        lengths[length] = lengths.get(length, 0) + 1\n",
    "    # Sort them in decreasing order\n",
    "    sorted_lengths = OrderedDict(sorted(lengths.items(), key=lambda t: t[1]*-1))\n",
    "    return lengths.values(), sorted_lengths\n",
    "lengths_train, _ = count_lengths(data_train)\n",
    "lengths_val, _ = count_lengths(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot lengths train\n",
    "fig = plt.figure()\n",
    "plt.plot(lengths_train)\n",
    "plt.xlabel('# words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Textual context size [TRAIN]')\n",
    "plt.savefig('/home/flipvanrijn/plots/textual-context-size-train.pdf', dpi=1000)\n",
    "\n",
    "# Plot lengths validation + test\n",
    "fig = plt.figure()\n",
    "plt.plot(lengths_val)\n",
    "plt.xlabel('# words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Textual context size [VAL]')\n",
    "plt.savefig('/home/flipvanrijn/plots/textual-context-size-val.pdf', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Zipf's distribution of length\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(sorted_lengths.values())\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77673"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c for l, c in lengths.items() if l <= 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zipf's Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pkl\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import wordpunct_tokenize, sent_tokenize\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def preprocess(s):\n",
    "    global stemmer\n",
    "\n",
    "    ns = []\n",
    "    for w in s:\n",
    "        if w:\n",
    "            w = stemmer.stem(w)\n",
    "            ns.append(w)\n",
    "\n",
    "    return ns\n",
    "\n",
    "def get_words(titles, descriptions, tags):\n",
    "    words = []\n",
    "    for i in xrange(len(titles)):\n",
    "        # Stem words and remove stopwords for title...\n",
    "        title = preprocess(titles[i].split(' '))\n",
    "        if title:\n",
    "            words += title\n",
    "        # ... description (for each sentence) ...\n",
    "        for desc in sent_tokenize(descriptions[i]):\n",
    "            desc = preprocess(desc.split(' '))\n",
    "            if desc:\n",
    "                words += desc\n",
    "        # ... and tagsc\n",
    "        ts = preprocess(tags[i])\n",
    "        if ts:\n",
    "            words += ts\n",
    "    return words\n",
    "\n",
    "words = []\n",
    "with open('/media/Data/flipvanrijn/datasets/coco/processed/reduced/coco_val_context.pkl') as f:\n",
    "    titles = pkl.load(f)\n",
    "    descriptions = pkl.load(f)\n",
    "    tags = pkl.load(f)\n",
    "words += get_words(titles, descriptions, tags)\n",
    "with open('/media/Data/flipvanrijn/datasets/coco/processed/reduced/coco_train_context.pkl') as f:\n",
    "    titles = pkl.load(f)\n",
    "    descriptions = pkl.load(f)\n",
    "    tags = pkl.load(f)\n",
    "words += get_words(titles, descriptions, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from string import lower\n",
    "from  itertools import *\n",
    "from pylab import *\n",
    "import seaborn\n",
    "tokens_with_count = Counter(imap(lower, words))\n",
    "counts = array(tokens_with_count.values())\n",
    "tokens = tokens_with_count.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "ranks = arange(1, len(counts)+1)\n",
    "indices = argsort(-counts)\n",
    "frequencies = counts[indices]\n",
    "loglog(ranks, frequencies, marker='.')\n",
    "title('Zipf plot for context')\n",
    "xlabel('Frequency rank of token')\n",
    "ylabel('Absolute frequency of token')\n",
    "grid(True)\n",
    "for n in list(logspace(-0.5, log10(len(counts)), 20).astype(int)):\n",
    "    dummy = text(ranks[n], frequencies[n], \" \" + tokens[indices[n]], verticalalignment=\"bottom\", horizontalalignment=\"left\")\n",
    "\n",
    "savefig('/home/flipvanrijn/plots/zipf-context.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Evaluate context using metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/flipvanrijn/Workspace/Dedicon-Thesis/server/pycocoevalcap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rouge.rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [(u'luang', 0.20321628880092443),\n",
    " (u'prabang', 0.2050751395771906),\n",
    " (u'199', 0.22953895277526),\n",
    " (u'this', 0),\n",
    " (u'dog', 0.15507775312144545),\n",
    " (u'loved', 0.1070854724854866),\n",
    " (u'to', 0),\n",
    " (u'sack', 0.2050751395771906),\n",
    " (u'out', 0),\n",
    " (u'on', 0),\n",
    " (u'the', 0),\n",
    " (u'shoe', 0.22634186845755885),\n",
    " (u'rack', 0.16392433862000122),\n",
    " (u'at', 0),\n",
    " (u'villa', 0.16745461600994188),\n",
    " (u'merry', 0.18885814309810428),\n",
    " (u'no', 0),\n",
    " (u'.', 0),\n",
    " (u'1', 0),\n",
    " (u'.', 0),\n",
    " (u'laos', 0.2974918213250064),\n",
    " (u'lao', 0.2974918213250064),\n",
    " (u'vacation', 0.11953598919265084),\n",
    " (u'travel', 0.10236591509290169),\n",
    " (u'trip', 0.11494678531178285),\n",
    " (u'luangprabang', 0.20234419599159267),\n",
    " (u'dog', 0.15507775312144545),\n",
    " (u'shoes', 0.22634186845755885),\n",
    " (u'cute', 0.12711024332054496)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d57c8fd35bf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcolored\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m232\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m253\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from colored import fg, bg\n",
    "colors = range(232, 253, 2)[::-1]\n",
    "scores = [s[1] for s in data]\n",
    "words = [s[0] for s in data]\n",
    "bins = np.linspace(0, 1, len(colors))\n",
    "pos = np.digitize(sc, bins)\n",
    "for w, p, s in zip(words, pos, scores):\n",
    "    if s > 0:\n",
    "        print('%s%s %s ' % (fg(255), bg(colors[p]), w)),\n",
    "    else:\n",
    "        print('%s%s %s ' % (fg('black'), bg(255), w)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255, 254, 253, 252, 251, 250, 249, 248, 247, 246, 245, 244, 243, 242, 241, 240, 239, 238, 237, 236, 235, 234, 233, 232]\n"
     ]
    }
   ],
   "source": [
    "print colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
